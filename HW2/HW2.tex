\documentclass[UTF8,fontset=windows]{ctexart}
\usepackage{fontspec}
\usepackage{xeCJK}
\usepackage{geometry}
\geometry{a4paper, scale=0.8}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
% \usepackage{luatexja} % Removed for compatibility

\usepackage{graphicx}
\usepackage{float}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{array}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newcommand{\emoji}[1]{\texttt{[#1]}}
\newcommand{\twemoji}[1]{\texttt{[#1]}}
\pagestyle{plain}
\lstset{
    language=Python,
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    frame=single
}

\title{%
  \heiti\bfseries\Large
  \textsf{DistilBERT} 推文情感分类实验报告%
}
\author{张以禾 \\ 学号：25800980010}
\date{2025年12月12日}

\setlength{\intextsep}{10pt plus 2pt minus 2pt}
\setlength{\textfloatsep}{10pt plus 2pt minus 2pt}

\begin{document}

\maketitle

\section{摘要}
本实验使用一种名为DistilBERT的BERT变体来自动识别人们在Twitter上发布文本的情绪状态。
通过探究DistilBERT的实现原理、数据预处理方法以及模型训练过程，评估其在情感分类任务中的表现。
通过微调预训练模型，实验结果显示DistilBERT在推文情感分类任务中取得了较高的准确率，证明了其在自然语言处理中的有效性。
同时，本文分析了在部分推文中模型预测错误的原因，并提出了未来改进的方向。

\section{引言}
随着社交媒体的普及，用户生成的内容如推文成为了情感分析的重要数据来源。
情感分析旨在识别和提取文本中的主观信息，帮助理解用户的情绪和态度。
近年来，预训练语言模型如BERT在自然语言处理任务中表现出色。
DistilBERT作为BERT的轻量级变体，通过知识蒸馏技术在保持性能的同时显著减少了模型大小和计算资源需求。
在本实验中，我们利用预训练的DistilBERT模型，理解Transformer架构的工作原理和数据的预处理及tokenization方法，并对预训练模型进行微调，
探究不同超参数对模型表现的影响并优化模型训练效果，基于训练结果分析分类的逻辑及错误分类样本的产生原因，最后生成5个对抗样本验证
原因的准确性，并提出可能的改进方案。

\section{实验方法}
\subsection{Task 1: 创建\texttt{token2idx}字典}
\subsubsection{问题重述}
本实验中，我们需要创建一个\texttt{token2idx}字典，将文本中的每个字符映射到一个唯一的整数索引。
\subsubsection{实验思路}
为了创建\texttt{token2idx}字典，我们首先需要遍历数据集中的所有文本，收集所有出现过的字符并按照一定顺序排序。
然后，我们为每个唯一字符分配一个整数索引，从0开始递增，并为特殊字符如填充符（\texttt{padding}）和未知字符（\texttt{unknown}）预留索引，
最后将字符与其对应的索引存储在一个字典中，及\texttt{token2idx}字典。

\subsection{Task 2: 完善提取隐藏层 \texttt{CLS} 特征的函数}
\subsubsection{问题重述}
在了解获取单个字符串的最后一个隐藏状态后，我们需要为整个数据集做同样的事情，创建一个新的\texttt{hidden\_state}列，存储所有这些向量。
在本实验中，我们需要完善一个函数，用于提取DistilBERT模型中每个输入字符串的\texttt{CLS}特征，即最后一层隐藏状态的第一个位置的向量表示。
\texttt{CLS}标记通常用于表示整个输入序列的语义信息，因此提取该特征对于下游任务如文本分类非常重要。
\subsubsection{实验思路}
为了提取整个数据集的\texttt{CLS}特征，我们可以遍历数据集中的每个文本样本，使用预训练的DistilBERT模型对每个样本进行前向传播，
并从模型的输出中提取\texttt{CLS}标记对应的隐藏状态向量，即最后一层隐藏状态的第一个位置。
我们将这些向量收集起来，并将提取的隐藏状态向量存储在一个新的列中，最终形成一个包含所有样本\texttt{CLS}特征的数据集。

\subsection{Task 3: 使用 \texttt{Scikit-Learn} 库中的模型对特征分类并比较不同模型的效果}
\subsubsection{问题重述}
在提取了\texttt{CLS}特征后，我们需要使用\texttt{Scikit-Learn}库中的不同分类模型对这些特征进行分类，并比较各个模型的效果。
\subsubsection{实验思路}
为了比较不同分类模型的效果，我们可以选择几种常用的分类算法，如逻辑回归、LinerSVM、RandomForest和决策树等。
对于每个模型，我们将使用提取的\texttt{CLS}特征作为输入，训练模型并评估其在验证集上的性能。
我们可以使用准确率、精确率、召回率和F1分数等指标来衡量模型的表现，并将各个模型的结果进行比较，以确定哪种模型在推文情感分类任务中表现最佳。

\subsection{Task 4: 探究超参数对模型表现的影响}
\subsubsection{问题重述}
在本实验中，我们需要探究不同超参数设置对模型表现的影响，以优化模型的训练效果。
\subsubsection{实验思路}
为了探究超参数对模型表现的影响，我们选择4个关键的超参数进行调整，包括学习率（\texttt{learning\_rate}）、
批量大小（\texttt{batch\_size}）、训练轮数（\texttt{num\_epochs}）和权重衰减（\texttt{weight\_decay}）。
我们可以通过网格搜索或随机搜索的方法，系统地调整这些超参数的值，并在验证集上评估模型的性能。
通过比较不同超参数组合下的模型表现，我们可以确定最佳的超参数设置，从而提升模型的分类效果。

\subsection{Task 5: 分析分类逻辑及错误分类样本的产生原因}
\subsubsection{问题重述}
在本实验中，我们需要分析模型的分类逻辑，并探讨错误分类样本产生的原因。
\subsubsection{实验思路}
为了分析分类逻辑，我们可以通过可视化模型的决策边界或使用特征重要性指标来理解模型的决策过程。
对于错误分类的样本，我们可以检查其文本内容，寻找可能导致误判的因素，如歧义、噪声或数据不平衡等。
通过深入分析这些错误样本，我们可以提出改进模型的策略，如数据增强、模型结构调整或引入更多上下文信息。

\subsection{Task 6: 生成对抗样本验证错误分类原因}
\subsubsection{问题重述}
在本实验中，我们需要生成对抗样本，以验证错误分类样本产生的原因。
\subsubsection{实验思路}
我们通过分析前一步骤中错误分类样本的特点，设计一些对抗样本，这些样本应包含可能导致模型误判的因素。
例如，我们可以创建包含讽刺、双关语或混合情绪表达的文本，以测试模型在处理这些复杂情感表达时的表现。
如果模型在对抗样本上表现出类似的错误分类行为，这将支持我们对错误分类原因的理解，并为未来的改进提供依据。

\section{实验}
\subsection{Task 1: 创建\texttt{token2idx}字典}
代码实现如代码\ref{func01}所示：
\begin{lstlisting}[
    caption={创建token2idx字典}, 
    label=func01
]
text = "Tokenizing text is a core task of NLP."

unique_chars = sorted(list(set("".join(text))))

specials = ["<PAD>", "<UNK>"]

all_tokens = specials + unique_chars
token2idx = {token: i for i, token in enumerate(all_tokens)}
\end{lstlisting}
\texttt{print(token2idx)}结果如\ref{res01}所示：
\begin{lstlisting}[
    caption={字典内容}, 
    label={res01}
]
    {'<PAD>': 0, '<UNK>': 1, ' ': 2, '.': 3, 'L': 4, 'N': 5, 
    'P': 6, 'T': 7, 'a': 8, 'c': 9, 'e': 10, 'f': 11, 'g': 12, 
    'i': 13, 'k': 14, 'n': 15, 'o': 16, 'r': 17, 's': 18, 't': 19, 
    'x': 20, 'z': 21}
\end{lstlisting}

\subsection{Task 2: 完善提取隐藏层 \texttt{CLS} 特征的函数}
代码实现如\ref{func02}所示：
\begin{lstlisting}[
    caption={提取隐藏层 CLS 特征函数}, 
    label={func02}
]
def extract_hidden_states(batch):

    inputs = {k: v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}

    with torch.no_grad():
        last_hidden_state = model(**inputs).last_hidden_state

    return {"hidden_state": last_hidden_state[:, 0].cpu().numpy()}
\end{lstlisting}

\subsection{Task 3: 使用 \texttt{Scikit-Learn} 库中的模型对特征分类并比较不同模型的效果}
为了更好的可读性，该实验代码单独放在了\texttt{classifier.py}文件中，详情见该文件，结果如图\ref{fig:task3}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./results/classifier_comparison.png}
    \caption{不同分类模型效果比较}
    \label{fig:task3}
\end{figure}

从图中可以看出，LinearSVM和LogisticRegression模型表现最佳，准确率均达到了63\%，而DecisionTree、ExtraTree和Dummy(Baseline)的表现相对较差。
但仍然值得注意的是分类时间。准确率较高的模型通常需要更长的训练时间，普遍在30秒左右，而Dummy(Baseline)模型虽然准确率最低，但训练时间最短，甚至达到了纳秒级别。
KNearest Neighbors和Random Forest模型在准确率和训练时间之间取得了较好的平衡，表现出中等的准确率和较快的训练速度。
至于Decision Tree，我很难想象为什么它能在13s的训练时长下仅达到35.85\%的准确率，和Dummy以及Extra Tree相差无几。

\subsection{Task 4: 探究超参数对模型表现的影响}
默认训练参数如\texttt{ref\{default\_params\}}所示：
\begin{table}[H]
    \centering
    \caption{默认训练参数}
    \label{default_params}
    \begin{tabular}{cc}
        \toprule
        参数 & 默认值 \\
        \midrule
        learning\_rate & 5e-5 \\
        training\_batch\_size & 8 \\
        eval\_batch\_size & 8 \\
        num\_of\_epochs & 5 \\
        weight\_decay & 0.01 \\
        \bottomrule
    \end{tabular}
\end{table}
我们仅修改\texttt{learning\_rate}、\texttt{training\_batch\_size}、\texttt{num\_of\_epochs}和\texttt{weight\_decay}四个参数，
其他参数均保持默认。
对于\texttt{learning\_rate}，实验结果如图\ref{fig:lr}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./plots/learning_rate.png}
    \caption{不同学习率设置对模型表现的影响}
    \label{fig:lr}
\end{figure}
从图中可以看出，模型在低学习率（如1e-5）时表现较好，而较高的学习率导致训练不稳定，准确率极低，可以认为模型在随机猜测。
同时我们注意到，该参数实际上为起始学习率，随着训练的进行会逐步减小。

对于\texttt{training\_batch\_size}，实验结果如图\ref{fig:bs}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./plots/per_device_train_batch_size.png}
    \caption{不同批量大小设置对模型表现的影响}
    \label{fig:bs}
\end{figure}
从图中可以发现，在较小的训练轮数下，小批量大小的表现更好，较大批量大小的准确率会有轻微下滑。但总体而言波动并不大。
如果考虑足够大的训练轮数，批量大小对模型表现的影响会进一步减小。该参数对模型的表现影响和训练轮数、学习率等参数密切相关，
需要综合考虑。

对于\texttt{num\_of\_epochs}，实验结果如图\ref{fig:epoch}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./plots/num_train_epochs.png}
    \caption{不同训练轮数设置对模型表现的影响}
    \label{fig:epoch}
\end{figure}
我们在实验中选择将epoch数量设置为从5起跳，2递增，以观察模型性能的提升情况。
在训练轮数大于5之后，准确率提升变得不明显甚至倒退，表明模型可能已经接近收敛。
对于该实验而言，训练轮数提升带来的准确率提升及其有限。
另外在实验早期，我们尝试过极小的训练轮数（1或2），此时模型的表现类似图\ref{fig:lr}中高学习率的情况，准确率极低，几乎可以认为就是在随机猜测。
因此我们认为训练轮数过少会导致模型无法充分学习数据特征，从而影响分类效果。且该参数的边际效应递减十分显著。

对于\texttt{weight\_decay}，实验结果如图\ref{fig:wd}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./plots/weight_decay.png}
    \caption{不同权重衰减设置对模型表现的影响}
    \label{fig:wd}
\end{figure}
考虑到权重衰减主要用于防止过拟合，在本实验中，数据集本身复杂度高，模型并未表现出明显的过拟合现象，
因此权重衰减对模型表现的影响较小，准确率在不同权重衰减设置下变化不大。
这也说明了主动增加数据集复杂度可以在一定程度上替代正则化手段，提升模型的泛化能力。


\textbf{我们为最终微调模型选择的超参数组合为：学习率8e-5，批量大小16，训练轮数5，权重衰减0.001。}

\subsection{Task 5: 分析分类逻辑及错误分类样本的产生原因}
在微调后的模型上进行测试（准确率93.6\%），我们收集了损失最大/最小的前十个样本进行分析。
损失最大的10个样本及预测情况如表\ref{tab:top10-loss}所示：
\begin{table}[H]
    \centering
    \caption{Top 10 Largest Loss Samples}
    \label{tab:top10-loss}
    \begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}X c c c p{1.7cm} p{2.0cm}}
        \toprule
        \textbf{文本} & \textbf{标签} & \textbf{预测} & \textbf{损失} & \textbf{标签名称} & \textbf{预测名称} \\
        \midrule
        when i was doing research a few months ago & 3 & 4 & 8.885772 & anger & fear \\
        \midrule
        i feel badly about reneging on my commitment to bring donuts to the faithful at holy family catholic church in columbus ohio & 2 & 1 & 9.060420 & love & joy \\
        \midrule
        i feel an overwhleming desire to say something completley moronic like hope your new year is a kick & 0 & 1 & 9.356089 & sadness & joy \\
        \midrule
        i will never forget as he shot the dye into me telling me ok youre going to feel a hot flash and then it will feel like youve pissed yourself & 2 & 3 & 9.377347 & love & anger \\
        \midrule
        my last genetices midterm a decent grade & 1 & 3 & 9.984397 & joy & anger \\
        \midrule
        i began to feel woeful as i stared into the abyss of goal less task less list less ness but luckily huda came to the rescue with in & 0 & 1 & 10.323510 & sadness & joy \\
        \midrule
        i feel i should say what i want since you are in fact reading my diary i feel that many of my beloved readers are becoming offended with some of the things i say and post here & 1 & 3 & 10.480444 & joy & anger \\
        \midrule
        im sure much of the advantage is psychological the feeling ive out clevered the competition who are now hopelessly burdened with their big chainring jump & 0 & 1 & 10.690640 & sadness & joy \\
        \midrule
        i feel that he was being overshadowed by the supporting characters & 2 & 0 & 12.114351 & love & sadness \\
        \midrule
        im kind of embarrassed about feeling that way though because my moms training was such a wonderfully defining part of my own life and i loved and still love & 2 & 0 & 12.130042 & love & sadness \\
        \bottomrule
    \end{tabularx}
\end{table}
损失最小的10个样本及预测情况如表\ref{tab:bottom10-loss}所示：
\begin{table}[H]
    \centering
    \caption{Top 10 Smallest Loss Samples}
    \label{tab:bottom10-loss}
    \begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}X c c c p{1.7cm} p{2.0cm}}
        \toprule
        \textbf{文本} & \textbf{标签} & \textbf{预测} & \textbf{损失} & \textbf{标签名称} & \textbf{预测名称} \\
        \midrule
        i feel when i am thrilled with my hair i have an extra bounce in my step and i don t worry about my outfit and make up as much & 1 & 1 & 0.000060 & joy & joy \\
        \midrule
        i have a feeling a forks version of that charming little tale will happen soon & 1 & 1 & 0.000060 & joy & joy \\
        \midrule
        i dont give a fuck because i feel like i cannot elicit any positive change or shifts within my current client load & 1 & 1 & 0.000061 & joy & joy \\
        \midrule
        i expected but it did feel hopeful and it definitely shed new light on her family & 1 & 1 & 0.000061 & joy & joy \\
        \midrule
        i am feeling more and more eager to get on with my move & 1 & 1 & 0.000061 & joy & joy \\
        \midrule
        i feel anything internally i m convinced that i m feeling my last breath heartbeat burp whatever & 1 & 1 & 0.000061 & joy & joy \\
        \midrule
        i shall move right along to the post interview portion of the day the results of which will be far more exciting and interesting to you i feel sure & 1 & 1 & 0.000061 & joy & joy \\
        \midrule
        i dont know what it is about me and sweets they make me feel bouncy and pleased with everything & 1 & 1 & 0.000061 & joy & joy \\
        \midrule
        i think about my life there is a strong feeling that im such a innocent skin deep young lady & 1 & 1 & 0.000061 & joy & joy \\
        \midrule
        i got to christmas feeling positive about the future and hopeful that hospital admissions were finally behind me & 1 & 1 & 0.000061 & joy & joy \\
        \bottomrule
    \end{tabularx}
\end{table}
通过对模型的分类逻辑进行分析，我们认为模型主要依靠能展示情绪关键词/词组进行判别。
例如，在损失最小的样本中，推文中包含明显的积极情绪词汇如“positive”、“thrilled”、“eager”、“hopeful”等，
使得模型能够准确地识别出其情感类别为“joy”，当然这也与数据集中极高的“joy”类别样本比例有关。
相反，损失最大的样本往往包含复杂或模糊的情感表达，缺乏明确的情绪指示词。
同时我们注意到，易被分错的样本中，模型往往会将负面情绪误判为正面情绪，或将中性情绪误判为负面情绪。
例如，模型在处理含有讽刺或双关语的推文时，往往难以正确理解其情感倾向，从而导致误判。
此外，推文中存在大量的缩写、拼写错误和非标准语言，这些因素也增加了模型理解文本的难度。
同时在一段文本中包含大量情绪色彩不同的词汇时，模型也容易产生混淆，导致错误分类。
通过检查错误分类的样本，我们发现许多样本包含模糊或复杂的情感表达，这使得模型难以准确捕捉其情绪。
此外，数据不平衡也是导致错误分类的一个重要原因，某些情感类别的样本数量较少，模型在训练过程中难以学习到这些类别的特征。
但是我们仍然无法理解为什么“when i was doing research a few months ago”会表示“anger”，这可能是数据本身的问题，
但也能体现在无情感提示词的情况下模型更有可能犯错。

整合所有数据并生成混淆矩阵，如图\ref{fig:confusion-matrix}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./analysis_results/confusion_matrix.png}
    \caption{混淆矩阵}
    \label{fig:confusion-matrix}
\end{figure}
重整化混淆矩阵，如图\ref{fig:normalized-confusion-matrix}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./analysis_results/confusion_matrix_normalized.png}
    \caption{重整化混淆矩阵}
    \label{fig:normalized-confusion-matrix} 
\end{figure}
从混淆矩阵中可以看出，模型在分类“joy”类别时表现最佳，而在分类“surprise”，“love”，“fear”类别时容易混淆。
个人认为，这与这些情感类别在文本中表达方式的相似性有关。

\subsection{Task 6: 生成对抗样本验证错误分类原因}
基于前述分析，我们创造了5个对抗样本，以验证错误分类的原因。
对抗样本及其预测结果如表\ref{tab:adversarial-samples}所示：
\begin{table}[H]
    \centering
    \caption{对抗样本及其预测结果}\label{tab:adversarial-samples}
    \begin{tabularx}{\textwidth}{c >{\raggedright\arraybackslash}X c c >{\raggedright\arraybackslash}X}
        \toprule
        \textbf{ID} & \textbf{文本} & \textbf{预期标签} & \textbf{预测标签} & \textbf{解释} \\
        \midrule
        1 & Great, another meeting canceled. Couldn't be more thrilled.\ \twemoji{face with rolling eyes} & anger & joy & 明显的讽刺（sarcasm）与反语表情，会让模型把文本字面情绪识别为正面。 \\
        \midrule
        2 & I laughed until I cried — best and worst night of my life. & sadness & sadness & 混合情绪描述（同时包含 laugh/cry），模型倾向于抓住强正面词汇如 'laughed'。 \\
        \midrule
        3 & I can't believe it! That surprise party actually made me so emotional. & surprise & surprise & 包含明显正面词汇（emotional / made me happy）可能导致模型判为 joy。 \\
        \midrule
        4 & Wow.\ \twemoji{crying face} & sadness & surprise & 文本极短，语境不足；emoji 可能被标记器当作噪声或与别的标签混淆。 \\
        \midrule
        5 & I'm so proud and terrified at the same time. & fear & joy & 同句包含相互冲突的情绪（proud vs terrified），单标签模型易被正面词覆盖。 \\
        \bottomrule
    \end{tabularx}
\end{table}
通过对这些对抗样本的分析，我们验证了之前对错误分类原因的理解。例如，第一个样本中的讽刺表达导致模型误判为“joy”，
而第二个样本中的混合情绪描述使模型难以准确分类。这些结果表明，模型在处理复杂情感表达时仍然存在挑战，
未来可以通过引入更多上下文信息和改进模型结构来提升其分类能力。

\section{结论}
本实验通过使用DistilBERT模型对Twitter推文进行情感分类，探究了模型的实现原理、数据预处理方法以及模型训练过程。
通过微调预训练模型，我们评估了不同分类模型的效果，并探讨了超参数对模型表现的影响。
实验结果显示，DistilBERT在推文情感分类任务中取得了较高的准确率，证明了其在自然语言处理中的有效性。
然而，模型在处理复杂或模糊的情感表达时仍然存在挑战，导致部分错误分类。
通过分析错误分类样本，我们发现讽刺、双关语以及数据不平衡是主要原因。
为了验证这些原因，我们生成了对抗样本，并观察模型的反应，进一步支持了我们的分析。
未来的工作可以集中在改进模型结构、引入更多上下文信息以及增强数据集，以提升模型在情感分类任务中的表现。

\section{问题}
本次使用的DistilBERT模型在处理推文情感分类任务中表现良好，以至于在调整超参数时难以观察到显著的性能差异。
这可能是由于模型已经接近其性能上限，或者数据集本身的复杂性不足以体现超参数调整的影响。

还有一个问题是，尽管模型在大多数样本上表现出色，但在处理包含讽刺、双关语或混合情绪表达的推文时，仍然存在一定的误判率。
这些复杂的情感表达形式可能超出了模型当前的理解能力，导致错误分类。

\section{实验环境}
本实验迁移到以下环境中进行：
\begin{itemize}
    \item 操作系统：Windows 11 25H2 26200.7171
    \item 编程语言：Python 3.13.11
    \item 环境管理工具：uv 0.9.17
    \item CUDA版本：13.0
    \item 主要库及版本：
    \begin{itemize}
        \item datasets 4.4.1
        \item huggingface-hub 0.36.0
        \item ipython 9.8.0
        \item matplotlib 3.10.7
        \item notebook 7.5.0
        \item pandas-stubs 2.3.3.251201
        \item scikit-learn 1.7.2
        \item torch 2.9.1
        \item transformers[torch] 4.57.3
        \item umap-learn 0.5.9.post2
    \end{itemize}
    \item 硬件配置：
    \begin{itemize}
        \item CPU：AMD Ryzen AI 9 HX370
        \item GPU：NVIDIA GeForce RTX 5060 Laptop
        \item 内存：32 GB LPDDR5 7500 MT/s
    \end{itemize}
\end{itemize}

\end{document}