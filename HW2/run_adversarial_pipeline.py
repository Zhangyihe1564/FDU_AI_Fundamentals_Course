# python
import os
import json
from transformers import pipeline
import torch

OUT_PATH = "adversarial_results.txt"
MODEL_DIR = "./finetuned_models/emotion_distilbert_ft"

adversarial_samples = [
    {
        "text": "Great, another meeting canceled. Couldn't be more thrilled ğŸ™„",
        "intended": "anger",
        "reason": "æ˜æ˜¾çš„è®½åˆºï¼ˆsarcasmï¼‰ä¸åè¯­è¡¨æƒ…ï¼Œä¼šè®©æ¨¡å‹æŠŠæ–‡æœ¬å­—é¢æƒ…ç»ªè¯†åˆ«ä¸ºæ­£é¢ã€‚"
    },
    {
        "text": "I laughed until I cried â€” best and worst night of my life.",
        "intended": "sadness",
        "reason": "æ··åˆæƒ…ç»ªæè¿°ï¼ˆåŒæ—¶åŒ…å« laugh/cryï¼‰ï¼Œæ¨¡å‹å€¾å‘äºæŠ“ä½å¼ºæ­£é¢è¯æ±‡å¦‚ 'laughed'ã€‚"
    },
    {
        "text": "I can't believe it! That surprise party actually made me so emotional.",
        "intended": "surprise",
        "reason": "åŒ…å«æ˜æ˜¾æ­£é¢è¯æ±‡ï¼ˆemotional / made me happyï¼‰å¯èƒ½å¯¼è‡´æ¨¡å‹åˆ¤ä¸º joyã€‚"
    },
    {
        "text": "Wow. ğŸ˜¢",
        "intended": "sadness",
        "reason": "æ–‡æœ¬æçŸ­ï¼Œè¯­å¢ƒä¸è¶³ï¼›emoji å¯èƒ½è¢«æ ‡è®°å™¨å½“ä½œå™ªå£°æˆ–ä¸åˆ«çš„æ ‡ç­¾æ··æ·†ã€‚"
    },
    {
        "text": "I'm so proud and terrified at the same time.",
        "intended": "fear",
        "reason": "åŒå¥åŒ…å«ç›¸äº’å†²çªçš„æƒ…ç»ªï¼ˆproud vs terrifiedï¼‰ï¼Œå•æ ‡ç­¾æ¨¡å‹æ˜“è¢«æ­£é¢è¯è¦†ç›–ã€‚"
    }
]

def load_classifier(model_dir):
    device = 0 if torch.cuda.is_available() else -1
    try:
        clf = pipeline("text-classification", model=model_dir, return_all_scores=True, device=device)
    except Exception as e:
        raise RuntimeError(f"æ— æ³•åŠ è½½æ¨¡å‹äº {model_dir}: {e}")
    return clf

def normalize_pred_label(pred_label, clf):
    lab = pred_label.lower()
    # å¦‚æœè¿”å›æ˜¯å½¢å¼ LABEL_Xï¼Œå°è¯•ç”¨æ¨¡å‹çš„ id2label æ˜ å°„
    if lab.startswith("label_"):
        try:
            idx = int(lab.split("_")[-1])
            id2label = getattr(clf.model.config, "id2label", None)
            if id2label and idx in id2label:
                return id2label[idx].lower()
        except Exception:
            pass
    return lab

def run_and_save(clf, samples, out_path):
    lines = []
    for i, s in enumerate(samples, 1):
        preds = clf(s["text"], return_all_scores=True)
        # pipeline è¿”å›ä¸€ä¸ª listï¼ˆbatchï¼‰; å•æ¡æ–‡æœ¬å–ç¬¬0ä¸ªå…ƒç´ 
        scores = preds[0]
        scores_sorted = sorted(scores, key=lambda x: x["score"], reverse=True)
        top = scores_sorted[0]
        pred_label = normalize_pred_label(top["label"], clf)
        top_score = top["score"]
        # build readable scores
        score_map = {normalize_pred_label(p["label"], clf): p["score"] for p in scores_sorted}
        fooled = pred_label != s["intended"].lower()
        entry = {
            "index": i,
            "text": s["text"],
            "intended": s["intended"],
            "predicted": pred_label,
            "predicted_score": float(top_score),
            "all_scores": {k: float(v) for k, v in score_map.items()},
            "fooled": bool(fooled),
            "explain": s["reason"]
        }
        lines.append(entry)
        # console short print
        print(f"[{i}] intended={s['intended']} predicted={pred_label} fooled={fooled}")
    # å†™æ–‡ä»¶ï¼ˆè¦†ç›–ï¼‰
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(lines, f, ensure_ascii=False, indent=2)
    print(f"ç»“æœå·²å†™å…¥ `{out_path}`")

def main():
    if not os.path.isdir(MODEL_DIR):
        raise FileNotFoundError(f"æ¨¡å‹ç›®å½•æœªæ‰¾åˆ°ï¼š `{MODEL_DIR}`")
    clf = load_classifier(MODEL_DIR)
    run_and_save(clf, adversarial_samples, OUT_PATH)

if __name__ == "__main__":
    main()
